{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest prediction of potential fire control locations (PCLs) for the 2018 Polecreek Fire, Utah (presented at the 2019 International Fire Ecology and Management Conference) \n",
    "\n",
    "Cite as: Hallema, D. W., O'Connor, C. J., Thompson, M. P., Sun, G., McNulty, S. G., Calkin, D. E. & Martin, K. L. (2019). Predicting fire line effectiveness with machine learning. 8th International Fire Ecology and Management Conference, *Association for Fire Ecology*, Tucson, Arizona, November 18-22, 2019. \n",
    "\n",
    "Author: [Dennis W. Hallema](https://www.linkedin.com/in/dennishallema) \n",
    "\n",
    "Description: Random Forest prediction of potential fire control locations (PCLs) for the 2018 Polecreek Fire in Utah. Prediction of PCLs is key to effective pre-fire planning and fire operations management. \n",
    "\n",
    "Depends: See `environment.yml`. \n",
    "\n",
    "Data: Topography, fuel characteristics, road networks and fire suppression \n",
    "\n",
    "Cite as: Hallema, D. W., O'Connor, C. J., Thompson, M. P., Sun, G., McNulty, S. G., Calkin, D. E. & Martin, K. L. (2019). Predicting fire line effectiveness with machine learning. 8th International Fire Ecology and Management Conference, *Association for Fire Ecology*, Tucson, Arizona, November 18-22, 2019. \n",
    "\n",
    "Acknowledgement: Funding was provided by the USDA Forest Service Rocky Mountain Research Station through an agreement between the USDA Forest Service Southern Research Station and North Carolina State University (agreement number 19-CS-11330110-075). \n",
    "\n",
    "Disclaimer: Use at your own risk. The authors cannot assure the reliability or suitability of these materials for a particular purpose. The act of distribution shall not constitute any such warranty, and no responsibility is assumed for a user's application of these materials or related materials. \n",
    "\n",
    "Content:\n",
    "\n",
    "* [Data preparation](#one) \n",
    "* [Random Forest (RF) classification](#two) \n",
    "* [Feature importance](#three) \n",
    "* [Classifier optimization](#four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation <a id='one'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from osgeo import gdal, gdal_array\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Binarizer, OrdinalEncoder\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raster input files\n",
    "features = [\n",
    "    'data/barrier.tif',\n",
    "    'data/costdist.tif',\n",
    "    'data/flatdist.tif',\n",
    "    'data/ridgedist.tif',\n",
    "    'data/valleydist.tif',\n",
    "    'data/roaddist.tif',\n",
    "    'data/DEM.tif',\n",
    "    'data/ros01.tif',\n",
    "    'data/rtc01.tif',\n",
    "    'data/sdi01.tif'\n",
    "]\n",
    "response = ['data/brt_resp2.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data labels\n",
    "feature_list = [str.split(features[i],\"/\")[-1] for i in range(len(features))]\n",
    "feature_list = [str.split(feature_list[i],\".\")[-2] for i in range(len(features))]\n",
    "response_list = [str.split(response[i],\"/\")[-1] for i in range(len(response))]\n",
    "response_list = [str.split(response_list[i],\".\")[-2] for i in range(len(response))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read response data\n",
    "ras_ds = gdal.Open(response[0], gdal.GA_ReadOnly)\n",
    "y = ras_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "# Read feature data\n",
    "X = np.zeros((ras_ds.RasterYSize, ras_ds.RasterXSize, len(features)), dtype=float)\n",
    "for b, f in enumerate(features):\n",
    "    ras_ds = gdal.Open(f, gdal.GA_ReadOnly)\n",
    "    X[:,:,b] = ras_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "print(\"Feature array dimensions: {}\".format(X.shape))\n",
    "print(\"Response array dimensions: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature maps\n",
    "plt.rcParams['figure.figsize'] = [12.8, 6.4]\n",
    "plt.rcParams['figure.dpi'] = 144\n",
    "fig, axes = plt.subplots(2,5)\n",
    "\n",
    "for i, ax in zip(range(X.shape[2]), axes.flatten()):\n",
    "    ax.imshow(X[:,:,i], cmap=plt.cm.Greys_r)\n",
    "    ax.set_title(str(feature_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot response map\n",
    "plt.rcParams['figure.figsize'] = [6.4, 4.8]\n",
    "plt.rcParams['figure.dpi'] = 144\n",
    "plt.imshow(y, cmap=plt.cm.Spectral)\n",
    "plt.title(str(response_list[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mask\n",
    "mask = Binarizer(threshold = -0.000001).fit_transform(y)\n",
    "for i in range(X.shape[2]):\n",
    "    X[:,:,i] = X[:,:,i] * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset training and testing maps\n",
    "X_train = X[1000:3000, 1000:3000, 0:X.shape[2]]\n",
    "y_train = y[1000:3000, 1000:3000]\n",
    "X_test = X[3000:4000, 1000:3000, 0:X.shape[2]]\n",
    "y_test = y[3000:4000, 1000:3000]\n",
    "\n",
    "print(\"X_train shape {}\".format(X_train.shape))\n",
    "print(\"y_train shape {}\".format(y_train.shape))\n",
    "print(\"X_test shape {}\".format(X_test.shape))\n",
    "print(\"y_test shape {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode response arrays\n",
    "y_train = OrdinalEncoder().fit_transform(y_train)\n",
    "y_test = OrdinalEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training map\n",
    "plt.rcParams['figure.figsize'] = [6.4, 4.8]\n",
    "plt.rcParams['figure.dpi'] = 144\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[:,:,1], cmap=plt.cm.Greys_r)\n",
    "plt.title('X (training)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(y_train, cmap=plt.cm.get_cmap('magma'))\n",
    "plt.title('y (training)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot testing map\n",
    "plt.rcParams['figure.figsize'] = [6.4, 4.8]\n",
    "plt.rcParams['figure.dpi'] = 144\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_test[:,:,0], cmap=plt.cm.Greys_r)\n",
    "plt.title('X (hold-out)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(y_test, cmap=plt.cm.get_cmap('magma'))\n",
    "plt.title('y (hold-out)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training feature histograms\n",
    "plt.rcParams['figure.figsize'] = [12.8, 6.4]\n",
    "plt.rcParams['figure.dpi'] = 144\n",
    "\n",
    "fig, axes = plt.subplots(2, 5)\n",
    "\n",
    "for i, ax in zip(range(X_train.shape[2]), axes.flatten()):\n",
    "    ax.hist(X_train[:,:,i])\n",
    "    ax.set_title('X_train {}'.format(feature_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training response histogram\n",
    "plt.rcParams['figure.figsize'] = [3.2, 2.4]\n",
    "plt.rcParams['figure.dpi'] = 144\n",
    "\n",
    "plt.hist(y_train)\n",
    "plt.title('y_train {}'.format(response_list[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classification <a id='two'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape arrays\n",
    "X_train_nx, X_train_ny, X_train_ns = X_train.shape\n",
    "X_train = X_train.reshape((X_train_nx * X_train_ny, X_train_ns))\n",
    "y_train_nx, y_train_ny = y_train.shape\n",
    "y_train = y_train.reshape((y_train_nx * y_train_ny))\n",
    "\n",
    "X_test_nx, X_test_ny, X_test_ns = X_test.shape\n",
    "X_test = X_test.reshape((X_test_nx * X_test_ny, X_test_ns))\n",
    "y_test_nx, y_test_ny = y_test.shape\n",
    "y_test = y_test.reshape((y_test_nx * y_test_ny))\n",
    "\n",
    "print(\"Dimensions of X_train: {}\".format(X_train.shape))\n",
    "print(\"Dimensions of y_train: {}\".format(y_train.shape))\n",
    "\n",
    "print(\"Dimensions of X_test: {}\".format(X_test.shape))\n",
    "print(\"Dimensions of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique value counts\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "counts = dict(np.transpose(np.asarray((unique_elements, counts_elements))))\n",
    "print(\"Unique value counts: {}\".format(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sample weights for unbalanced classes as inverse of probability\n",
    "counts_sum = float(sum(counts.values()))\n",
    "p_max = max(counts.values())\n",
    "weights = dict((x, float(p_max)/float(y)) for x, y in counts.items())\n",
    "sample_weight = [weights.get(i, i) for i in y_train]\n",
    "print(\"Sample weights: {}\".format(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier\n",
    "clf = RandomForestClassifier(n_estimators = 50, random_state=21, n_jobs = -2, verbose=2, max_features=None)\n",
    "\n",
    "# Fit classifier to training set\n",
    "clf = clf.fit(X_train, y_train, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute training metrics\n",
    "accuracy = clf.score(X_train, y_train)\n",
    "\n",
    "#  Predict labels of test set\n",
    "train_pred = clf.predict(X_train)\n",
    "\n",
    "# Compute MSE, confusion matrix, classification report\n",
    "mse = mean_squared_error(y_train, train_pred)\n",
    "conf_mat = confusion_matrix(y_train.round(), train_pred.round())\n",
    "clas_rep = classification_report(y_train.round(), train_pred.round())\n",
    "\n",
    "# Print reports\n",
    "print('{:=^80}'.format('RF training report'))\n",
    "print('Accuracy: %.4f' % accuracy)\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print(\"Confusion matrix:\\n{}\".format(conf_mat))\n",
    "print(\"Classification report:\\n{}\".format(clas_rep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to read the above confusion matrix:\n",
    "\n",
    "|           | Prediction: 0 (Unaffected)           | Prediction: 1 (BA)         | Prediction: 2 (PCL)          |\n",
    "|-----------|--------------------------------------|----------------------------|------------------------------|\n",
    "| Actual: 0 (Unaffected) | __Unaffected classified as unaffected__ | Unaffected classified as BA  | Unaffected classified as PCL |\n",
    "| Actual: 1 (BA) | BA classified as unaffected   | __BA classified as BA__  | BA classified as PCL        |\n",
    "| Actual: 2 (PCL) | PCL classified as unaffected   | PCL classified as BA      | __PCL classified as PCL__    |\n",
    "\n",
    "BA = Burned area; PCL = Potential fire control location \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute testing metrics\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "# Predict labels of test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute MSE, confusion matrix, classification report\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test.round(), y_pred.round())\n",
    "clas_rep = classification_report(y_test.round(), y_pred.round())\n",
    "\n",
    "# Print reports\n",
    "print('{:=^80}'.format('RF testing report'))\n",
    "print('Accuracy: %.4f' % accuracy)\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print(\"Confusion matrix:\\n{}\".format(conf_mat))\n",
    "print(\"Classification report:\\n{}\".format(clas_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities\n",
    "y_pred_prob = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape arrays\n",
    "X_train = X_train.reshape(X_train_nx, X_train_ny, X_train_ns)\n",
    "y_train = y_train.reshape(y_train_nx, y_train_ny)\n",
    "train_pred = train_pred.reshape(y_train_nx, y_train_ny)\n",
    "\n",
    "X_test = X_test.reshape(X_test_nx, X_test_ny, X_test_ns)\n",
    "y_test = y_test.reshape(y_test_nx, y_test_ny)\n",
    "y_pred = y_pred.reshape(y_test_nx, y_test_ny)\n",
    "\n",
    "print(\"Dimensions of X_train: {}\".format(X_train.shape))\n",
    "print(\"Dimensions of y_train: {}\".format(y_train.shape))\n",
    "print(\"Dimensions of train_pred: {}\".format(train_pred.shape))\n",
    "\n",
    "print(\"Dimensions of X_test: {}\".format(X_test.shape))\n",
    "print(\"Dimensions of y_test: {}\".format(y_test.shape))\n",
    "print(\"Dimensions of y_pred: {}\".format(y_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training data and prediction maps\n",
    "plt.rcParams['figure.figsize'] = [12.8, 9.6]\n",
    "plt.rcParams['figure.dpi'] = 144\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(y_train, cmap=plt.cm.get_cmap('magma'))\n",
    "plt.title('y (training)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(train_pred, cmap=plt.cm.get_cmap('magma'))\n",
    "plt.title('y (training predicted)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test data and prediction maps\n",
    "plt.rcParams['figure.figsize'] = [12.8, 9.6]\n",
    "plt.rcParams['figure.dpi'] = 144\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(y_test, cmap=plt.cm.get_cmap('magma'))\n",
    "plt.title('y (hold-out)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(y_pred, cmap=plt.cm.get_cmap('magma'))\n",
    "plt.title('y (predicted)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of test data and prediction\n",
    "plt.rcParams['figure.figsize'] = [9.6, 4.8]\n",
    "plt.rcParams['figure.dpi'] = 108\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(y_test.flatten())\n",
    "plt.title('y (hold-out)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(y_pred.flatten())\n",
    "plt.title('y (predicted)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predicted condition arrays\n",
    "y_pred_00 = (y_test.round() == 0) & (y_pred.round() == 0)\n",
    "y_pred_01 = (y_test.round() == 0) & (y_pred.round() == 1)\n",
    "y_pred_02 = (y_test.round() == 0) & (y_pred.round() == 2)\n",
    "\n",
    "y_pred_10 = (y_test.round() == 1) & (y_pred.round() == 0)\n",
    "y_pred_11 = (y_test.round() == 1) & (y_pred.round() == 1)\n",
    "y_pred_12 = (y_test.round() == 1) & (y_pred.round() == 2)\n",
    "\n",
    "y_pred_20 = (y_test.round() == 2) & (y_pred.round() == 0)\n",
    "y_pred_21 = (y_test.round() == 2) & (y_pred.round() == 1)\n",
    "y_pred_22 = (y_test.round() == 2) & (y_pred.round() == 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted condition maps\n",
    "plt.rcParams['figure.figsize'] = [12.8, 9.6]\n",
    "plt.rcParams['figure.dpi'] = 144\n",
    "\n",
    "plt.subplot(331)\n",
    "plt.imshow(y_pred_00, cmap=plt.cm.terrain)\n",
    "plt.title('*Unaffected classified as unaffected*')\n",
    "\n",
    "plt.subplot(332)\n",
    "plt.imshow(y_pred_01, cmap=plt.cm.terrain)\n",
    "plt.title('Unaffected classified as BA')\n",
    "\n",
    "plt.subplot(333)\n",
    "plt.imshow(y_pred_02, cmap=plt.cm.terrain)\n",
    "plt.title('Unaffected classified as PCL')\n",
    "\n",
    "plt.subplot(334)\n",
    "plt.imshow(y_pred_10, cmap=plt.cm.terrain)\n",
    "plt.title('BA classified as unaffected')\n",
    "\n",
    "plt.subplot(335)\n",
    "plt.imshow(y_pred_11, cmap=plt.cm.terrain)\n",
    "plt.title('*BA classified as BA*')\n",
    "\n",
    "plt.subplot(336)\n",
    "plt.imshow(y_pred_12, cmap=plt.cm.terrain)\n",
    "plt.title('BA classified as PCL')\n",
    "\n",
    "plt.subplot(337)\n",
    "plt.imshow(y_pred_20, cmap=plt.cm.terrain)\n",
    "plt.title('PCL classified as unaffected')\n",
    "\n",
    "plt.subplot(338)\n",
    "plt.imshow(y_pred_21, cmap=plt.cm.terrain)\n",
    "plt.title('PCL classified as BA')\n",
    "\n",
    "plt.subplot(339)\n",
    "plt.imshow(y_pred_22, cmap=plt.cm.terrain)\n",
    "plt.title('*PCL classified as PCL*')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance <a id='three'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = list(clf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 4)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort feature importance in descending order\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print feature importance\n",
    "_ = [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of relative importance\n",
    "plt.rcParams['figure.figsize'] = [6.4, 4.8]\n",
    "plt.rcParams['figure.dpi'] = 108\n",
    "\n",
    "X_values = list(range(len(importances)))\n",
    "plt.bar(X_values, importances, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "plt.xticks(X_values, feature_list, rotation = 'vertical')\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Variable')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features sorted by decreasing importance\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "\n",
    "# Cumulative importance\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "\n",
    "# Create line plot\n",
    "plt.plot(X_values, cumulative_importances, 'b-')\n",
    "plt.hlines(y = 0.95, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "plt.xticks(X_values, sorted_features, rotation = 'vertical')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Cumulative Importance')\n",
    "plt.title('Cumulative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features explaining 95% cum. importance\n",
    "n_import = np.where(cumulative_importances > 0.95)[0][0] + 1\n",
    "print('Number of features required (95% importance):', n_import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier optimization <a id='four'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the names of most important features\n",
    "important_feature_names = [feature[0] for feature in feature_importances[0:(n_import - 1)]]\n",
    "\n",
    "# Column indices of most important features\n",
    "important_indices = [feature_list.index(feature) for feature in important_feature_names]\n",
    "\n",
    "# Create training and testing sets with only important features\n",
    "X_train_imp = X_train[:, :, important_indices]\n",
    "X_test_imp = X_test[:, :, important_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape arrays\n",
    "X_train_imp_nx, X_train_imp_ny, X_train_imp_ns = X_train_imp.shape\n",
    "X_train_imp = X_train_imp.reshape((X_train_imp_nx * X_train_imp_ny, X_train_imp_ns))\n",
    "y_train_nx, y_train_ny = y_train.shape\n",
    "y_train = y_train.reshape((y_train_nx * y_train_ny))\n",
    "\n",
    "X_test_imp_nx, X_test_imp_ny, X_test_imp_ns = X_test_imp.shape\n",
    "X_test_imp = X_test_imp.reshape((X_test_imp_nx * X_test_imp_ny, X_test_imp_ns))\n",
    "y_test_nx, y_test_ny = y_test.shape\n",
    "y_test = y_test.reshape((y_test_nx * y_test_ny))\n",
    "\n",
    "print(\"Dimensions of X_train: {}\".format(X_train_imp.shape))\n",
    "print(\"Dimensions of y_train: {}\".format(y_train.shape))\n",
    "print(\"Dimensions of X_test: {}\".format(X_test_imp.shape))\n",
    "print(\"Dimensions of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit classifier to training set\n",
    "clf = clf.fit(X_train_imp, y_train, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute training metrics\n",
    "accuracy = clf.score(X_train_imp, y_train)\n",
    "\n",
    "#  Predict labels of test set\n",
    "train_pred = clf.predict(X_train_imp)\n",
    "\n",
    "# Compute MSE, confusion matrix, classification report\n",
    "mse = mean_squared_error(y_train, train_pred)\n",
    "conf_mat = confusion_matrix(y_train.round(), train_pred.round())\n",
    "clas_rep = classification_report(y_train.round(), train_pred.round())\n",
    "\n",
    "# Print reports\n",
    "print('{:=^80}'.format('RF training report'))\n",
    "print('Accuracy: %.4f' % accuracy)\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print(\"Confusion matrix:\\n{}\".format(conf_mat))\n",
    "print(\"Classification report:\\n{}\".format(clas_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute testing metrics\n",
    "accuracy = clf.score(X_test_imp, y_test)\n",
    "\n",
    "# Predict labels of test set\n",
    "y_pred = clf.predict(X_test_imp)\n",
    "\n",
    "# Compute MSE, confusion matrix, classification report\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test.round(), y_pred.round())\n",
    "clas_rep = classification_report(y_test.round(), y_pred.round())\n",
    "\n",
    "# Print reports\n",
    "print('{:=^80}'.format('RF testing report'))\n",
    "print('Accuracy: %.4f' % accuracy)\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print(\"Confusion matrix:\\n{}\".format(conf_mat))\n",
    "print(\"Classification report:\\n{}\".format(clas_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities\n",
    "y_pred_prob = clf.predict_proba(X_test_imp)[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
